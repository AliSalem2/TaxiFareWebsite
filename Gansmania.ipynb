{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gansmania",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliSalem2/TaxiFareWebsite/blob/master/Gansmania.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d030uXc9kjud"
      },
      "source": [
        "# GAN MODELS AND TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k51_Zqqkh79"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuWT_IzJhxIX"
      },
      "source": [
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from matplotlib import pyplot\n",
        "from IPython.display import clear_output\n",
        "import os\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SW1VdsThxOF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5QoJ3fPiCvK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l53oQluXh9Mx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N31i-qTfhxTM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xOqIwj6d7-R"
      },
      "source": [
        "from google.colab import drive\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O36BqVHpd8N7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17af09a2-9f96-4193-8558-3c123e9df539"
      },
      "source": [
        "drive.mount(\"/content/gdrive\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIAs4i8Od8ZT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI1d3Gm5kVyY"
      },
      "source": [
        "## Step 2 importing the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxUg-oUKd8kB"
      },
      "source": [
        "gallery = \"gdrive/MyDrive/Colab Notebooks/data/Abstract_gallery\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJLEFv0ekMuJ"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt \n",
        "import numpy as np\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "def inv_sigmoid(x):\n",
        "    return np.log(y/(1-y))\n",
        "%matplotlib inline\n",
        "path = gallery\n",
        "os.getcwd()\n",
        "img_list = os.listdir(path)\n",
        "def access_images(img_list,path,length):\n",
        "    pixels = []\n",
        "    imgs = []\n",
        "    for i in range(length):\n",
        "        img = Image.open(path+'/'+img_list[i],'r')\n",
        "        basewidth = 100\n",
        "        img = img.resize((basewidth,basewidth), Image.ANTIALIAS)\n",
        "        pix = np.array(img.getdata())\n",
        "        pixels.append(pix.reshape(100,100,3))\n",
        "        imgs.append(img)\n",
        "    return np.array(pixels),imgs\n",
        "def show_image(pix_list):\n",
        "    array = np.array(pix_list.reshape(100,100,3), dtype=np.uint8)\n",
        "    new_image = Image.fromarray(array)\n",
        "    new_image.show()\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6qLtNnKhvgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec0cd4d-ee82-4818-c7df-212217abbf17"
      },
      "source": [
        "pixels,imgs = access_images(img_list,path,1000)\n",
        "pixels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94a4HXW5gLzD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0182c0c-432a-456a-82a8-b1d97370b22b"
      },
      "source": [
        "os.getcwd()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw2uvYtMgMAQ"
      },
      "source": [
        "def define_discriminator(in_shape = (100,100,3)):\n",
        "    #This discriminator takes in the list of fake and real images as input and returns a single value between 0 and 1. If the value is closer to 0, the computer thinks the image is real. If it comes closer to 1, the computer thinks the image is fake.\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVqXQDu5iDhU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxz7t4HRifip"
      },
      "source": [
        "## Step 4| Define Generator:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooaNfD3-iDnI"
      },
      "source": [
        "def define_generator(latent_dim):\n",
        "    # The generator takes in a random point from latent space and takes it as an input. \n",
        "    # It upscales the latent point to the appropriate shape of 100,100,3, that can then be displayed as an image.\n",
        "    model = Sequential()\n",
        "    n_nodes = 128 * 25 * 25\n",
        "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((25, 25, 128)))\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(3, (7,7) , padding='same'))\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VubMIet7iDrb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZaS6CE-jLUo"
      },
      "source": [
        "## Step 5| Define GAN:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbKaswxKiZJX"
      },
      "source": [
        "def define_gan(g_model, d_model):\n",
        "    # Linking the two models together gives the GAN, the complete model. The output of the generator is fed into the discriminator. It is then trained using these values.\n",
        "    d_model.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(g_model)\n",
        "    model.add(d_model)\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkVgBP4NjOc1"
      },
      "source": [
        "##  Step 6| Generate Parts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2nZ4OCuiZNd"
      },
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "    #This calls upon the real and fake samples and generates the latent points that are used as the input for the generator.\n",
        "    ix = randint(0, dataset.shape[0], n_samples)\n",
        "    X = dataset[ix]\n",
        "    y = ones((n_samples, 1))\n",
        "    return X, y\n",
        " \n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    X = g_model.predict(x_input)\n",
        "    y = zeros((n_samples, 1))\n",
        "    return X, y"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0PZV1ayiZQo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydN7fJc0jaoc"
      },
      "source": [
        "## Step 7| Train:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjxUvtLSiZTl"
      },
      "source": [
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=10):\n",
        "    \n",
        "    #Remember that the two models are programmed to work against each other. \n",
        "    #During training, the computer will print out the loss for each of the models. \n",
        "    #Whichever value has the lowest loss is technically winning the competition. \n",
        "    #This allows you to see when the balance between both of the models is breaking down.\n",
        "    \n",
        "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "    print(dataset.shape[0])\n",
        "    half_batch = int(n_batch / 2)\n",
        "    for i in range(n_epochs):\n",
        "        for j in range(bat_per_epo):\n",
        "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
        "            d_loss, _ = d_model.train_on_batch(X, y)\n",
        "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "            y_gan = ones((n_batch, 1))\n",
        "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
        "        if (i+1) % 10 == 0:\n",
        "            summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
        "            clear_output()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ee4iUjsjeRC"
      },
      "source": [
        "## Step 8| Summarize Performance:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_UGvJsriZWj"
      },
      "source": [
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
        "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "    filename = 'generator_model_%03d.h5' % (epoch + 1)\n",
        "    g_model.save(filename)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF3bRjgVu4P9"
      },
      "source": [
        "pixels,imgs = access_images(img_list,path,1000)\n",
        "pixels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e-sHQ-sjzeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "d1ea24e5-18b5-40fa-aa83-11eefb10ef2d"
      },
      "source": [
        "latent_dim = 4\n",
        "d_model = define_discriminator()\n",
        "g_model = define_generator(latent_dim)\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "print(pixels.shape)\n",
        "train(g_model, d_model, gan_model, np.array(pixels), latent_dim)\n",
        "print(pixels)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-99a6823d5621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgan_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pixels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmCKgtUUjjIG"
      },
      "source": [
        "## Step 10| Visualize Image generations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfHzz5Hcjjb5"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from numpy.random import randn\n",
        "from matplotlib import pyplot\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5c-bhSFjjhj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbA0hnKsjjkn"
      },
      "source": [
        "#This script actually runs the program. \n",
        "#For perspective on computation time, I use a windows surface pro.100 epochs takes \n",
        "#about 2 hours for a batch_size as defined in the code above.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsrMkeUDjjnk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "c100df55-4761-4457-b35b-9f323aa31dac"
      },
      "source": [
        "model = g_model\n",
        "latent_points = generate_latent_points(100,1)\n",
        "X = model.predict(latent_points)\n",
        "array = np.array(X.reshape(100,100,3), dtype=np.uint8)\n",
        "new_image = Image.fromarray(array)\n",
        "new_image.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-c3462757b1e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlatent_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnew_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'g_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo47r-g9jjp-"
      },
      "source": [
        "plt.imshow(new_image)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}